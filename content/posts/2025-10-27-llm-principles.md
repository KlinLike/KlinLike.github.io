---
title: "LLM基本原理及思考"
date: 2025-10-27T15:07:20+08:00
categories: [工具与流程]
tags: [ai, llm]
---

# 前言
近日我参加了一个主题为人工智能在开发中应用的集会，会上接触到了不少使用LLM完成工作的方法，方法太多以至于让我分不清那些才是真正有价值的东西。于是我决定回归基本，重新梳理一下LLM的基本知识，希望这有助于让我找出真正有价值的想法，忽略余下的“噪音”。
后面我会写涉及具体方法的笔记，这里先总结一下基础知识。

# 原理

## Transfomer
当下LLM的核心架构，在Transformer出现之前，处理序列的主流框架是RNN或LSTM，但RNN必须按照顺序处理单词，很难并行计算，效率低下。

Transformer架构完全抛弃了顺序依赖，允许模型并行处理输入。如果没有**并行**处理架构，用当下的算力来处理海量数据是无法想象的。

## 自注意力机制
自注意力可以说是LLM最**核心**的算法。

核心思想：在处理一个词（比如 "bank"）时，注意力机制会动态地去“关注”句子中所有其他词（比如 "river" 或 "money"），并计算一个“相关性分数”。这样，模型就能准确理解 "bank" 在当前上下文中的确切含义。

*稀疏注意力是这个机制的一个重要优化，因为原始的注意力机制需要计算每个词与所有其他词的关系，当上下文窗口变得非常大时，计算量会爆炸。*

## 规模效应与涌现
核心思想：研究者发现，当你持续增加三样东西——模型参数量（神经元数量）、训练数据量、计算量——模型的性能不仅会平滑提升，而且在达到某个巨大规模的“临界点”后，会突然 “涌现” 出之前完全不具备的新能力（比如上下文学习、逻辑推理、代码生成等）。


## 预训练 + 微调
这是 LLM 的“生产流水线”，分为两个主要阶段：

1. **自监督预训练 (Self-Supervised Pre-training)**：这是最耗钱耗时的一步。把互联网上能找到的海量文本（万亿级别的单词量）喂给模型，让它做一个极其简单的任务：“预测下一个词”。通过这个过程，模型 “被迫” 学会了语法、事实、常识，甚至初步的推理能力。

2. **指令微调与对齐 (Instruction Tuning & RLHF)**：预训练的模型像一个知识渊博但 “野性未驯” 的大脑。这一步是 “教它做人” 。
   - 指令微调：用大量“问题-答案”的数据集来训练它，让它学会“听指挥”。
   - RLHF (基于人类反馈的强化学习)：这是让模型变得“有用且无害”的关键。通过人类对模型生成的答案进行排序打分，模型会学习如何生成更符合人类偏好和价值观的回答。

## 上下文窗口
核心思想：它定义了模型在一次交互中能“看到”或“记住”多少文本（token）。早期的模型可能只有2048个 token（约等于1500个英文单词），而现在（2025年）的模型动辄几十万甚至上百万 token。

更大的上下文窗口意味着模型可以处理更长的文档、进行更复杂的对话、保持更久的记忆，这是 LLM 从“玩具”走向“实用工具”的关键一步。

# 从“道”和“术”角度去理解当下LLM使用的技巧

## “术”会过时，而“道”具有持久性
它们是什么：
- **术（技巧）**：当下的最佳Prompt模板、思维链、RAG最佳实践，是基于当前这一代模型的特性和局限性总结出来的经验公式。
- **道（原理）**：模型的底层架构、训练目标、对齐机制等基本原理。

举个例子：为什么现在我们需要思维链作为提示词？

- **“术”的层面**：因为你加上这句话，LLM 的回答质量会更高。
- **“道”的层面**：因为 LLM 是一个自回归模型，它生成一个 token 依赖于前面所有的 token。你给它一个“请逐步思考”的指令，相当于在它的“上下文窗口”中强行注入了一个“规划阶段”，迫使它在生成最终答案（Answer）之前，先生成中间的“思考过程”（Thinking），而这些“思考过程”又会作为下一步推理的输入，从而极大地提高了复杂推理的准确性。

*自回归模型的核心思想是：它预测下一个值，是基于它自己过去生成的所有值。*

当未来的模型在架构上原生内置了更强的推理和规划能力时，“思维链”这个“术”可能就不再是必需的了，甚至会过时。但是，你对“自回归模型如何利用上下文进行推理”这个“道”的理解，是永远不会过时的。

## “术”决定了应用的下限，“道”决定了创新的上限
- **掌握“术”**：能让你成为一个高效的 LLM 使用者或“Prompt 工程师”。你能熟练地使用这个工具，完成80分的工作。
- **掌握“道”**：能让你成为一个 LLM 构建者（Builder）或架构师（Architect）。你不仅知道怎么用，还知道它的“能力边界”在哪里，知道如何通过工程化的手段（比如 Fine-tuning、RAG 架构、Agent 框架）来弥补它的短板。